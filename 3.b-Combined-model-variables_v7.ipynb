{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from github\n",
    "url=''\n",
    "#url = 'https://raw.githubusercontent.com/MariaRosendal/Enhancing-Price-Momentum-with-RNN/main/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing input and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market variables (train data)\n",
    "input_market_train = pd.read_csv(url+'market_train.csv')\n",
    "input_market_train.rename(columns={input_market_train.columns[0]: \"date\" }, inplace = True)\n",
    "input_market_train['date'] =  pd.to_datetime(input_market_train['date'])\n",
    "\n",
    "# Market variables (test data)\n",
    "input_market_test = pd.read_csv(url+'market_test.csv')\n",
    "input_market_test.rename(columns={input_market_test.columns[0]: \"date\" }, inplace = True)\n",
    "input_market_test['date'] =  pd.to_datetime(input_market_test['date'])\n",
    "\n",
    "input_market = pd.merge(input_market_train, input_market_test, \n",
    "                          on=['date', 'Mkt', 'Mkt_cumret', 'Mkt_std'], how='outer')\n",
    "\n",
    "# Stock variables\n",
    "\n",
    "# Return\n",
    "input_ret = pd.read_csv(url+'input_ret.csv')\n",
    "input_ret.rename(columns={input_ret.columns[0]: \"date\" }, inplace = True)\n",
    "input_ret['date'] =  pd.to_datetime(input_ret['date'])\n",
    "\n",
    "# Cum. Return\n",
    "input_ret_cum = pd.read_csv(url+'input_ret_cum.csv')\n",
    "input_ret_cum.rename(columns={input_ret_cum.columns[0]: \"date\" }, inplace = True)\n",
    "input_ret_cum['date'] =  pd.to_datetime(input_ret_cum['date'])\n",
    "\n",
    "# Standard deviation\n",
    "input_std = pd.read_csv(url+'input_std.csv')\n",
    "input_std.rename(columns={input_std.columns[0]: \"date\" }, inplace = True)\n",
    "input_std['date'] =  pd.to_datetime(input_std['date'])\n",
    "\n",
    "# Alpha\n",
    "input_alpha = pd.read_csv(url+'input_alpha.csv')\n",
    "input_alpha.rename(columns={input_alpha.columns[0]: \"date\" }, inplace = True)\n",
    "input_alpha['date'] =  pd.to_datetime(input_alpha['date'])\n",
    "\n",
    "# Beta\n",
    "input_beta = pd.read_csv(url+'input_beta.csv')\n",
    "input_beta.rename(columns={input_beta.columns[0]: \"date\" }, inplace = True)\n",
    "input_beta['date'] =  pd.to_datetime(input_beta['date'])\n",
    "\n",
    "# Idiosyncratic momentum\n",
    "input_idio = pd.read_csv(url+'input_idio.csv')\n",
    "input_idio.rename(columns={input_idio.columns[0]: \"date\" }, inplace = True)\n",
    "input_idio['date'] =  pd.to_datetime(input_idio['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ret.shape, input_ret_cum.shape, input_std.shape, input_alpha.shape, input_beta.shape, input_idio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_var_cols = []\n",
    "for col in input_ret.columns:\n",
    "  stock_var_lst = [list(stock) for stock in zip(input_ret[col], input_ret_cum[col], input_std[col], input_alpha[col], input_beta[col],input_idio[col])]\n",
    "  stock_var_cols.append(stock_var_lst)\n",
    "\n",
    "stock_var = pd.DataFrame(stock_var_cols).T\n",
    "stock_var.columns = input_ret.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_var['date'] = input_ret['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lag date column one month back (i.e. move features one month foward, so we are predicting next month)\n",
    "stock_var_lagged = stock_var.copy()\n",
    "stock_var_lagged['date'] = stock_var.loc[:,'date'].shift(-1)\n",
    "stock_var_lagged.drop(stock_var_lagged.tail(1).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = pd.read_csv(url+'universe.csv')\n",
    "universe['date'] =  pd.to_datetime(universe['date'])\n",
    "universe['permno'] = universe['permno'].astype(str)\n",
    "universe.permno.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test and train universe\n",
    "universe_train = universe[universe['date'] > '1930-12-01']\n",
    "universe_train = universe_train[universe_train['date'] <= '1975-12-01']\n",
    "universe_test = universe[universe['date'] > '1975-12-01']\n",
    "\n",
    "# Save as CSV\n",
    "universe_train.to_csv('universe_train.csv', index=False)\n",
    "universe_test.to_csv('universe_test.csv',  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_train.shape, universe_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In keras LSTM the time flows from top to bottom\n",
    "# Assuming the lookback for features is 12-1M\n",
    "\n",
    "X_test = []\n",
    "counter = 0\n",
    "for (dt, permno), _data in universe_test.groupby(['date', 'permno']):\n",
    "        if counter%672==0:\n",
    "            print(counter, '/', len(universe_test.groupby(['date', 'permno'])))\n",
    "        counter += 1\n",
    "        # Construct LSTM features\n",
    "        market = input_market.loc[\n",
    "            input_market['date'] <= dt].tail(12)\n",
    "\n",
    "        stock_variables = stock_var_lagged.loc[\n",
    "            stock_var_lagged[\"date\"] <= dt\n",
    "            ][[\"date\", permno]].tail(12)\n",
    "\n",
    "        merged = market.merge(stock_variables, on=\"date\")\n",
    "        merged[['ret','cum_ret', 'std', 'alpha', 'beta', 'idio']] = pd.DataFrame(merged[permno].tolist(), index= merged.index)\n",
    "        features = merged[[\"Mkt\", \"Mkt_cumret\", \"Mkt_std\", 'ret','cum_ret', 'std', 'alpha', 'beta', 'idio']].values\n",
    "\n",
    "        X_test.append(features)\n",
    "\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling variables cross-sectionally (stock variables only)\n",
    "idx_stock_features_begin = 3\n",
    "num_permno = 500\n",
    "time_steps = 12\n",
    "num_stock_features = 6\n",
    "\n",
    "for i in range(len(X_test)//num_permno):\n",
    "    for t in range(time_steps):\n",
    "        for f in range(num_stock_features):\n",
    "            ranks = np.argsort(np.argsort(X_test[i*num_permno:i*num_permno+num_permno,t,idx_stock_features_begin:][:,f]))\n",
    "            X_test[i*num_permno:i*num_permno+num_permno,t,idx_stock_features_begin:][:,f] = [-1 + (2/(num_permno-1))*rank for rank in ranks]\n",
    "X_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_test, open('X_test_scaled.pkl', \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring no NaN values\n",
    "np.count_nonzero(np.isnan(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all variables\n",
    "\n",
    "X_train = []\n",
    "counter = 0\n",
    "for (dt, permno), _data in universe_train.groupby(['date', 'permno']):\n",
    "        if counter%672==0:\n",
    "            print(counter, '/', len(universe_train.groupby(['date', 'permno'])))\n",
    "        counter += 1\n",
    "        # Construct LSTM features\n",
    "        market = input_market.loc[\n",
    "            input_market['date'] <= dt].tail(12)\n",
    "\n",
    "        stock_variables = stock_var_lagged.loc[\n",
    "            stock_var_lagged[\"date\"] <= dt\n",
    "            ][[\"date\", permno]].tail(12)\n",
    "\n",
    "        merged = market.merge(stock_variables, on=\"date\")\n",
    "        merged[['ret','cum_ret', 'std', 'alpha', 'beta', 'idio']] = pd.DataFrame(merged[permno].tolist(), index= merged.index)\n",
    "        features = merged[[\"Mkt\", \"Mkt_cumret\", \"Mkt_std\", 'ret','cum_ret', 'std', 'alpha', 'beta', 'idio']].values\n",
    "\n",
    "        X_train.append(features)\n",
    "\n",
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting variables cross-sectionally (stock variables only)\n",
    "idx_stock_features_begin = 3\n",
    "num_permno = 500\n",
    "time_steps = 12\n",
    "num_stock_features = 6\n",
    "\n",
    "for i in range(len(X_train)//num_permno):\n",
    "    for t in range(time_steps):\n",
    "        for f in range(num_stock_features):\n",
    "            ranks = np.argsort(np.argsort(X_train[i*num_permno:i*num_permno+num_permno,t,idx_stock_features_begin:][:,f]))\n",
    "            X_train[i*num_permno:i*num_permno+num_permno,t,idx_stock_features_begin:][:,f] = [-1 + (2/(num_permno-1))*rank for rank in ranks]\n",
    "X_train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(np.isnan(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_train, open('X_train_scaled.pkl', \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP and RF variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vec = []\n",
    "counter = 0\n",
    "for (dt, permno), _data in universe_test.groupby(['date', 'permno']):\n",
    "        if counter%672==0:\n",
    "            print(counter, '/', len(universe_test.groupby(['date', 'permno'])))\n",
    "        counter += 1\n",
    "        # Construct features\n",
    "        market = input_market.loc[\n",
    "            input_market['date'] <= dt].tail(1)\n",
    "\n",
    "        stock_variables = stock_var_lagged.loc[\n",
    "            stock_var_lagged[\"date\"] <= dt\n",
    "            ][[\"date\", permno]].tail(1)\n",
    "\n",
    "        merged = market.merge(stock_variables, on=\"date\")\n",
    "        merged[['ret','cum_ret', 'std', 'alpha', 'beta', 'idio']] = pd.DataFrame(merged[permno].tolist(), index= merged.index)\n",
    "        features = merged[[\"Mkt\", \"Mkt_cumret\", \"Mkt_std\", 'ret','cum_ret', 'std', 'alpha', 'beta', 'idio']].values\n",
    "\n",
    "        X_test_vec.append(features)\n",
    "\n",
    "X_test_vec = np.array(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling variables cross-sectionally (stock variables only)\n",
    "idx_stock_features_begin = 3\n",
    "num_permno = 500\n",
    "time_steps = 1\n",
    "num_stock_features = 6\n",
    "\n",
    "for i in range(len(X_test_vec)//num_permno):\n",
    "    for t in range(time_steps):\n",
    "        for f in range(num_stock_features):\n",
    "            ranks = np.argsort(np.argsort(X_test_vec[i*num_permno:i*num_permno+num_permno,t,idx_stock_features_begin:][:,f]))\n",
    "            X_test_vec[i*num_permno:i*num_permno+num_permno,t,idx_stock_features_begin:][:,f] = [-1 + (2/(num_permno-1))*rank for rank in ranks]\n",
    "X_test_vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring no NaN values\n",
    "np.count_nonzero(np.isnan(X_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_test_vec, open('X_test_vec.pkl', \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all variables\n",
    "\n",
    "X_train_vec = []\n",
    "counter = 0\n",
    "for (dt, permno), _data in universe_train.groupby(['date', 'permno']):\n",
    "        if counter%672==0:\n",
    "            print(counter, '/', len(universe_train.groupby(['date', 'permno'])))\n",
    "        counter += 1\n",
    "        # Construct features\n",
    "        market = input_market.loc[\n",
    "            input_market['date'] <= dt].tail(1)\n",
    "\n",
    "        stock_variables = stock_var_lagged.loc[\n",
    "            stock_var_lagged[\"date\"] <= dt\n",
    "            ][[\"date\", permno]].tail(1)\n",
    "\n",
    "        merged = market.merge(stock_variables, on=\"date\")\n",
    "        merged[['ret','cum_ret', 'std', 'alpha', 'beta', 'idio']] = pd.DataFrame(merged[permno].tolist(), index= merged.index)\n",
    "        features = merged[[\"Mkt\", \"Mkt_cumret\", \"Mkt_std\", 'ret','cum_ret', 'std', 'alpha', 'beta', 'idio']].values\n",
    "\n",
    "        X_train_vec.append(features)\n",
    "\n",
    "X_train_vec = np.array(X_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting variables cross-sectionally (stock variables only)\n",
    "idx_stock_features_begin = 3\n",
    "num_permno = 500\n",
    "time_steps = 1\n",
    "num_stock_features = 6\n",
    "\n",
    "for i in range(len(X_train_vec)//num_permno):\n",
    "    for t in range(time_steps):\n",
    "        for f in range(num_stock_features):\n",
    "            ranks = np.argsort(np.argsort(X_train_vec[i*num_permno:i*num_permno+num_permno,t,idx_stock_features_begin:][:,f]))\n",
    "            X_train_vec[i*num_permno:i*num_permno+num_permno,t,idx_stock_features_begin:][:,f] = [-1 + (2/(num_permno-1))*rank for rank in ranks]\n",
    "X_train_vec  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(np.isnan(X_train_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_train_vec, open('X_train_vec.pkl', \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
