{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://raw.githubusercontent.com/MariaRosendal/Enhancing-Price-Momentum-with-RNN/main/'\n",
    "url= \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "#seed_value= 123\n",
    "#import os\n",
    "#os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "#import random\n",
    "#random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "#import numpy as np\n",
    "#np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "#import tensorflow as tf\n",
    "#tf.random.set_seed(seed_value)\n",
    "\n",
    "# 5. For layers that introduce randomness like dropout, make sure to set seed values \n",
    "#model.add(Dropout(0.25, seed=seed_value))\n",
    "#6 Configure a new global `tensorflow` session\n",
    "#from keras import backend as K\n",
    "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "#K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing input and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import X \n",
    "X_train = pickle.load(open('X_train_scaled.pkl', 'rb' ))\n",
    "X_test = pickle.load(open('X_test_scaled.pkl', 'rb' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import X for MLP and RF \n",
    "#X_train_mlp = pickle.load(open('X_train_vec.pkl', 'rb' ))\n",
    "#X_test_mlp = pickle.load(open('X_test_vec.pkl', 'rb' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for NaN values\n",
    "print(np.count_nonzero(np.isnan(X_train)), np.count_nonzero(np.isnan(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((270000, 12, 9), (270000, 12, 9))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing y\n",
    "y = pd.read_csv(url+'y_reg.csv')\n",
    "y['date'] =  pd.to_datetime(y['date'])\n",
    "y = y.set_index(['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining length of y_train and y_test\n",
    "y_train = y[y.index <= '1975-12-01']\n",
    "y_test = y[y.index > '1975-12-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((270000, 1), (270000, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((270000,), (270000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reformating y\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.134864,  0.201948,  0.036379, ..., -0.072761, -0.051312,\n",
       "        0.030733])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import BatchNormalization \n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping X to vectors\n",
    "n_input = X_train.shape[1] * X_train.shape[2]\n",
    "X_train_mlp = X_train.reshape(len(X_train),n_input)\n",
    "X_test_mlp = X_test.reshape(len(X_test),n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_lin = LinearRegression()\n",
    "m_lin.fit(X_train_mlp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_predict = m_lin.predict(X_test_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.00 RMSE\n",
      "0.0009594408586506351\n",
      "-0.057806861150169864\n"
     ]
    }
   ],
   "source": [
    "testScore = math.sqrt(mean_squared_error(y_test, lin_predict))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "print(testScore)\n",
    "print((r2_score(y_test, lin_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    270000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = pd.DataFrame(lin_predict)\n",
    "lin.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lin_predict, open('lin_predict.pkl', 'wb' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((270000, 108), (270000, 108))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mlp.shape,  X_test_mlp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring data keeps temporal element when split\n",
    "tscv = TimeSeriesSplit(n_splits=9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters_rf = {'n_estimators':[50, 100, 200, 300], 'max_depth':[3, 5, 7], 'min_samples_split':[3, 5, 10, 50]}\n",
    "param_opt = dict(max_depth=Integer(1,10), max_features=Integer(3,108))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    }
   ],
   "source": [
    "bayesian = BayesSearchCV(\n",
    "     m_rf,\n",
    "     param_opt,\n",
    "     n_iter=32,\n",
    "     random_state=100,\n",
    "     cv=tscv,\n",
    "     verbose = 0, n_jobs=1\n",
    " )\n",
    "\n",
    "bayesian_result = bayesian.fit(X_train_mlp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to BayesianOptimization the best parameters are : \n",
      "max_depth : 1\n",
      "max_features : 3\n"
     ]
    }
   ],
   "source": [
    "# Best model parameters\n",
    "print('According to BayesianOptimization the best parameters are : ')\n",
    "print('max_depth : ' + str(bayesian_result.best_params_['max_depth']))\n",
    "print('max_features : ' + str(bayesian_result.best_params_['max_features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.002944 using OrderedDict([('max_depth', 1), ('max_features', 3)])\n",
      "-0.021947 (0.034739) with: OrderedDict([('max_depth', 5), ('max_features', 21)])\n",
      "-0.026370 (0.045516) with: OrderedDict([('max_depth', 4), ('max_features', 46)])\n",
      "-0.030857 (0.055087) with: OrderedDict([('max_depth', 5), ('max_features', 60)])\n",
      "-0.027277 (0.042697) with: OrderedDict([('max_depth', 8), ('max_features', 36)])\n",
      "-0.038808 (0.061843) with: OrderedDict([('max_depth', 5), ('max_features', 77)])\n",
      "-0.031985 (0.053647) with: OrderedDict([('max_depth', 2), ('max_features', 77)])\n",
      "-0.044281 (0.064545) with: OrderedDict([('max_depth', 7), ('max_features', 72)])\n",
      "-0.017745 (0.025772) with: OrderedDict([('max_depth', 6), ('max_features', 10)])\n",
      "-0.026307 (0.045355) with: OrderedDict([('max_depth', 6), ('max_features', 53)])\n",
      "-0.035861 (0.048723) with: OrderedDict([('max_depth', 9), ('max_features', 26)])\n",
      "-0.007457 (0.010530) with: OrderedDict([('max_depth', 2), ('max_features', 8)])\n",
      "-0.029266 (0.068707) with: OrderedDict([('max_depth', 1), ('max_features', 108)])\n",
      "-0.003112 (0.004914) with: OrderedDict([('max_depth', 1), ('max_features', 3)])\n",
      "-0.006111 (0.008611) with: OrderedDict([('max_depth', 3), ('max_features', 3)])\n",
      "-0.002944 (0.004832) with: OrderedDict([('max_depth', 1), ('max_features', 3)])\n",
      "-0.121353 (0.128973) with: OrderedDict([('max_depth', 10), ('max_features', 108)])\n",
      "-0.006251 (0.006982) with: OrderedDict([('max_depth', 1), ('max_features', 37)])\n",
      "-0.004770 (0.005248) with: OrderedDict([('max_depth', 1), ('max_features', 15)])\n",
      "-0.003737 (0.005160) with: OrderedDict([('max_depth', 1), ('max_features', 3)])\n",
      "-0.014847 (0.026255) with: OrderedDict([('max_depth', 8), ('max_features', 3)])\n",
      "-0.020114 (0.029160) with: OrderedDict([('max_depth', 10), ('max_features', 3)])\n",
      "-0.050777 (0.065818) with: OrderedDict([('max_depth', 10), ('max_features', 53)])\n",
      "-0.076358 (0.116248) with: OrderedDict([('max_depth', 4), ('max_features', 108)])\n",
      "-0.013541 (0.023352) with: OrderedDict([('max_depth', 1), ('max_features', 55)])\n",
      "-0.006284 (0.007259) with: OrderedDict([('max_depth', 1), ('max_features', 25)])\n",
      "-0.009779 (0.017010) with: OrderedDict([('max_depth', 5), ('max_features', 3)])\n",
      "-0.018943 (0.041544) with: OrderedDict([('max_depth', 1), ('max_features', 90)])\n",
      "-0.014733 (0.018448) with: OrderedDict([('max_depth', 2), ('max_features', 30)])\n",
      "-0.067703 (0.081628) with: OrderedDict([('max_depth', 10), ('max_features', 79)])\n",
      "-0.013986 (0.026727) with: OrderedDict([('max_depth', 1), ('max_features', 72)])\n",
      "-0.018266 (0.028232) with: OrderedDict([('max_depth', 3), ('max_features', 15)])\n",
      "-0.005510 (0.008355) with: OrderedDict([('max_depth', 2), ('max_features', 3)])\n"
     ]
    }
   ],
   "source": [
    "# Selecting best model\n",
    "print(\"Best: %f using %s\" % (bayesian_result.best_score_, bayesian_result.best_params_))\n",
    "means = bayesian_result.cv_results_['mean_test_score']\n",
    "stds = bayesian_result.cv_results_['std_test_score']\n",
    "params = bayesian_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining best model parameters\n",
    "max_depth = bayesian_result.best_params_['max_depth']\n",
    "max_features = bayesian_result.best_params_['max_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=1, max_features=1, n_estimators=300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "best_rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=max_depth)\n",
    "\n",
    "best_rf.fit(X_train_mlp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest:\t\t\t-0.0001377252949832375\n"
     ]
    }
   ],
   "source": [
    "print(\"Random forest:\\t\\t\\t\" + str(best_rf.score(X_test_mlp, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predict = best_rf.predict(X_test_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0001377252949832375\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, rf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_df = pd.DataFrame()\n",
    "r2_df['y'] = y_test\n",
    "r2_df['y_hat'] = rf_predict\n",
    "r2_df['difference'] = (r2_df['y']-r2_df['y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006583800648086169\n"
     ]
    }
   ],
   "source": [
    "r2_df = pd.DataFrame()\n",
    "r2_df['y'] = y_test\n",
    "r2_df['y_hat'] = rf_predict\n",
    "r2_df['difference'] = (r2_df['y']-r2_df['y_hat'])\n",
    "r2_df['y_2'] = r2_df['y']**2\n",
    "r2_df['dif2'] = r2_df['difference']**2\n",
    "y_2 = r2_df['y_2'].sum() \n",
    "dif2 = r2_df['dif2'].sum()\n",
    "print(1 - (dif2 / y_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    269351\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = pd.DataFrame(rf_predict)\n",
    "rf.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_predict, open('rf_predict.pkl', 'wb' ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
